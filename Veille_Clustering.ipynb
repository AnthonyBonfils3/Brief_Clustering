{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with K-means\n",
    "\n",
    "compétences: c1 c2 c3 c4 c5 c20\n",
    "Keywords: Unsupervised Learning, Clustering, Kmeans.\n",
    "\n",
    "## Description\n",
    "\n",
    "Découvrir l'apprentissage non-supervisé au travers de l'algorithme K-means.\n",
    "\n",
    "## Contexte\n",
    "\n",
    "L'apprentissage supervisé ce présente comme une approche de l'apprentissage automatique qui permet de découvrir la structure sous-jacente des données en l'absence d'étiquetage, c'est à dire sans catégories ou classe connue en avance.\n",
    "\n",
    "Afin de se familiariser avec cette approche et mieux l'appréhender pour l'utiliser dans des scénario plus complexe, les objectifs sont les suivants : \n",
    "* Nous souhaitons comprendre le principe de cette technique et les scénarios d'utilisation\n",
    "* Expérimenter et évaluer un algorithme de cet classe de problème d'apprentissage : les  K-moyennes (ou K-means) sur un jeu de données simple.\n",
    "* Comprendre et comparer les métrique d'évaluation en jeux\n",
    "* tester sur des jeux précédemment utilisé de classification, la capacité de l'algorithme à retrouver les catégories de prédiction.\n",
    "\n",
    "\n",
    "Question de veilles:\n",
    "\n",
    "Qu'est ce que le clustering ?\n",
    "Est ce un probleme difficile ? pourquoi ?\n",
    "* qu'elle est la compléxité d'un probléme de clustering ?\n",
    "Quelle sont les métrique utilisé pour le clustering ?\n",
    "* Ecriver en une phrase votre comprhéension pour chaque métrique découverte\n",
    "* séparer les métrique avec \"ground truth\" et \"sans \"ground truth\".\n",
    "* différenc entre NMI et AMI ?\n",
    "\n",
    "## Ressources\n",
    "\n",
    "* https://le-datascientist.fr/apprentissage-supervise-vs-non-supervise\n",
    "* https://realpython.com/k-means-clustering-python/#writing-your-first-k-means-clustering-code-in-python\n",
    "* (fr) https://mrmint.fr/algorithme-k-means\n",
    "* https://scikit-learn.org/stable/modules/clustering.html#clustering\n",
    "* https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation\n",
    "\n",
    "\n",
    "\n",
    "## Livrable\n",
    "\n",
    "Un git par apprenant avec les éléments suivants:\n",
    "1. Un notebook, résumant le travail\n",
    "\n",
    "## Modalité pédagogique\n",
    "\n",
    "durée: 2 jours\n",
    "groupe: individuel\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Réponces aux questions de veille\n",
    "\n",
    "### **Qu'est ce que le clustering ?**\n",
    "\n",
    "La mise en cluster consiste à séparer ou à diviser un ensemble de données en un certain nombre de groupes, de sorte que les ensembles de données appartenant aux mêmes groupes se ressemblent davantage que ceux d’autres groupes. En termes simples, l’objectif est de séparer les groupes ayant des traits similaires et de les assigner en grappes.\n",
    "\n",
    "C'est un problème d'apprentissage **non-supervisé**. Les données ne sont pas labelisées, ce qui est le cas en général car: couteux (payer une personne pour le faire, en temps...), fastidieux et cela peux être mal fait.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **est-ce un probleme difficile ? pourquoi ? Donnez la compléxité en temps et mémoire.**\n",
    "\n",
    "Le clustering est un problème difficile car :\n",
    "* la plupart du temps on ne dispose pas de la réalité terrain (ground thruth)\n",
    "* Pour le clustering hiérarchique les algorithmes font évoluer le nombre de clusters **k**, or pour le clustering non-hiérarchique (partitionnement) il faut détermeiner ce **k -> Il n'y a pas de \"formule magique\"**\n",
    "* L'initiation des algorithme peux être compliqué et pour certains algorithmes comme le Kmeans (ou d'autre) peux faire varier les résultats.\n",
    "* L'évaluation est difficile, notament lorsqu'on ne dispose pas des **vrais** labels.\n",
    "\n",
    "la compléxité en temps et mémoire :\n",
    "\n",
    "Le clustering non-hierarchique (KMeans ou autre) est plus efficace en temps de calcul (complexité O(K*n*d) que le clustering hierarchique qui a une (complexité algorithmique O(K*n2*d) rien que pour le calcul des distances)\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Quelle sont les métrique utilisé pour le clustering ?**\n",
    "\n",
    "Liste non exhaustive des métriques utilisées pour le clustering :\n",
    "* Rand index (adjusted or unadjusted)\n",
    "* Mutual Information based scores (Normalised : NMI and Adjusted : AMI)\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Ecrivez en une phrase votre compréhension pour 3 métrique métrique ground truth (dont MNI) 3 sans ground truth (dont silouhette)**\n",
    "    * **donner en une phrase l'intuition derrièr ces mesure.**\n",
    "\n",
    "#### Métrique avec ground thruth:\n",
    "* Rand index (adjusted) : contraire de l'inertie\n",
    "<br>$\\displaystyle{RI=\\frac{a+b}{{C_2}^{n_samples}}}$ \n",
    "<br>where \n",
    "\n",
    "    * a, the number of pairs of elements that are in the same set in C and in the same set in K\n",
    "    * n\n",
    "    b, the number of pairs of elements that are in different sets in C and in different sets in K\n",
    "    * where ${C_2}^{n_samples}$ is the total number of possible pairs in the dataset. It does not matter if the calculation is performed on ordered pairs or unordered pairs as long as the calculation is performed consistently.\n",
    "\n",
    "* Rand index (unadjusted) \n",
    "<br>$\\displaystyle{ARI = \\frac{RI - E[RI]}{max(RI) - E[RI]}}$\n",
    "<br>\n",
    "* Mutual Information based scores (Normalised : NMI and Adjusted : AMI)\n",
    "$\\displaystyle{MI(U,V)=\\sum_{i=1}^{|U|}\\sum_{i=1}^{|V|}\\frac{U_i \\cap V_i}{}\\log\\Big(\\frac{N|U_i \\cap V_i|}{|U_i| |V_i|}\\Big)}$\n",
    "<br>\n",
    "$\\displaystyle{NMI(U,V)=\\frac{MI(U,V)}{mean(H(U),H(V))}}$\n",
    "<br>\n",
    "<br>\n",
    "where $\\displaystyle{H(U)=-\\sum_{i=1}^{|U|} \\frac{|U_i|}{N}log\\Big(\\frac{|U_i|}{N}\\Big)}$ and $\\displaystyle{H(V)=-\\sum_{i=1}^{|V|} \\frac{|V_i|}{N}log\\Big(\\frac{|V_i|}{N}\\Big)}$\n",
    "<br>\n",
    "$\\displaystyle{AMI(U,V)=\\frac{MI(U,V) - E[MI]}{mean(H(U),H(V)) - E[MI]}}$\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Métrique avec ground thruth:\n",
    "\n",
    "* Silhouette\n",
    "\n",
    "* Calinski-Harabasz Index\n",
    "\n",
    "* Davies-Bouldin Index\n",
    "\n",
    "<br>\n",
    "\n",
    "### **différence entre NMI et AMI ?**\n",
    "\n",
    "Normalised or Ajusted MI : \n",
    "\n",
    "NMI : normalisé \"contre le hasard\"\n",
    "\n",
    "AMI : normalisé et centrée autour  de l'esperence mathématique.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Application au digits\n",
    "cf fichier **Apply_Clustering_to_digit_recognation.ipynb**\n",
    "\n",
    "## 3. Application au sentiments\n",
    "cf fichier **Apply_Clustering_to_sentiments_analysis.ipynb**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
